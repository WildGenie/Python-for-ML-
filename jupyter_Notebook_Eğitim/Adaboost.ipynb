{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Adaboost.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBco_Y0xDxOh"
      },
      "source": [
        "#DERS 19- ADABOOST \n",
        "\n",
        "Rastgele binlerce kişiye karmaşık bir soru sorduğunuzu varsayalım ve cevaplarını toplayalım. Çoğu zaman, bu toplu cevabın bir uzmanın cevabından daha iyi olduğunu göreceksiniz.Benzer şekilde, bir grubun tahminlerini (sınıflayıcılar veya regresörler gibi) toplarsanız, genellikle en iyi bireyselden daha iyi tahminler alırsınız.Bir grup şeklinde olan tahmin algoritmalarına ensemble denir; bu nedenle, bu tekniğe Ensemble Learning denir ve bir Ensemble Learning algoritmasına Ensemble yöntemi denir.\n",
        "\n",
        "Adaboost\n",
        "Yeni bir predictor(tahminci) bir önceki tahmini düzeltmesinin bir yolu, bir önceki tahminin uyguladığı eğitim durumlarına biraz daha dikkat etmektir. Bu, zor durumlara giderek daha fazla odaklanan yeni tahminlerle sonuçlanır. AdaBoost tarafından kullanılan teknik budur. Örneğin, bir AdaBoost sınıflandırıcısı oluşturmak için, birinci temel sınıflandırıcı eğitilir ve eğitim seti hakkında tahminlerde bulunmak için kullanılır. Yanlış sınıflandırılmış eğitim durumlarının nispi ağırlığı artırılır ve bizim için daha değerli hale gelir. İkinci bir sınıflandırıcı, güncellenmiş ağırlıklar kullanılarak eğitilir ve yine antrenman setinde tahminler yapar, ağırlıklar güncellenir bu özellik son aşamaya kadar tekrar edilir.\n",
        "\n",
        "Tüm modeller eğitildikten sonra, ensemble tahmin yapmayı, bagging veya pastinge benzer şekilde yapar, ancak modeller, ağırlıklı eğitim setindeki genel doğruluklarına bağlı olarak farklı ağırlıklara sahiptir.\n",
        "\n",
        "Not: Bu sıralı öğrenme tekniğinin önemli bir dezavantajı vardır: Paralelleştirilemez , çünkü her tahminci yalnızca önceki modele göre eğitilip değerlendirildikten sonra eğitilebilir. Sonuç olarak, bagging veya pasting gibi ölçeklenmez.(Şeekiller) \n",
        "\n",
        "Detaylı Okuma: https://medium.com/@oguzkircicek/ensemble-learning-7ec8c9a7227f\n",
        "\n",
        "Bu çalışmada, meme kanseri veri setini inceleyecek ve kişinin meme kanseri olup olmadığını tahmin etmek için modeli eğitmeye çalışacağız. Weak learner kullanacağız yani maksimum derinliği =2 olan bir karar ağacı diyebiliriz.\n",
        "\n",
        "Daha sonra weak learner'ları 3'er 3'er arttırarak en iyi modeli bulmaya çalışacağız.\n",
        "\n",
        "Kütüphaneleri yükleyerek başlayalım."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDuvH00cDxOk"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn import metrics\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwlrIDZkDxOw"
      },
      "source": [
        "Meme kanseri veri setini kullanarak kişinin kanser olup olmadığını bulmaya çalışacağız. Bağımlı değişkenimiz target.\n",
        "Aşağıdaki veri setindeki bağımsız değişkenlere baktığımızda anlayabilmek için bir doktor olmamız gerekebilirdi.\n",
        "Ancak makine öğrenmesinde veriler ile iş yaptığımızdan bu işin uzmanı olmamıza gerek yok. Gerekli örüntüyü yakalayıp modeli\n",
        "kurduğumuzda başarılı sonuçlar elde edebiliriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5rOD1wzDxO0"
      },
      "source": [
        "cancer = load_breast_cancer() # verinin yüklenmesi\n",
        "digits = load_digits()\n",
        "\n",
        "data = cancer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-ysx0ThDxO-"
      },
      "source": [
        "df = pd.DataFrame(data= np.c_[data['data'], data['target']],\n",
        "                     columns= list(data['feature_names']) + ['target'])\n",
        "df['target'] = df['target'].astype('uint16') # bağımlı değişkenin veri tipinin belirlenmesi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r98BZBXdDxPM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "4e20b9e5-36cc-4022-bbde-5d70f208014a"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0          17.99         10.38  ...                  0.11890       0\n",
              "1          20.57         17.77  ...                  0.08902       0\n",
              "2          19.69         21.25  ...                  0.08758       0\n",
              "3          11.42         20.38  ...                  0.17300       0\n",
              "4          20.29         14.34  ...                  0.07678       0\n",
              "..           ...           ...  ...                      ...     ...\n",
              "564        21.56         22.39  ...                  0.07115       0\n",
              "565        20.13         28.25  ...                  0.06637       0\n",
              "566        16.60         28.08  ...                  0.07820       0\n",
              "567        20.60         29.33  ...                  0.12400       0\n",
              "568         7.76         24.54  ...                  0.07039       1\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyqcxO3DDxPY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "da2eb984-9903-4326-a5dc-baea4c3343a6"
      },
      "source": [
        "df.head() #verinin ilk 5 satırı"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0        17.99         10.38  ...                  0.11890       0\n",
              "1        20.57         17.77  ...                  0.08902       0\n",
              "2        19.69         21.25  ...                  0.08758       0\n",
              "3        11.42         20.38  ...                  0.17300       0\n",
              "4        20.29         14.34  ...                  0.07678       0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xzsiP57DxPj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "af85cd16-5475-44c2-9cf6-3d3ffa84c505"
      },
      "source": [
        "# bağımsız ve bağımlı değişkenlerin birbirinden ayırılması\n",
        "X = df.drop('target', axis=1)\n",
        "y = df[['target']]\n",
        "\n",
        "# verinin train ve test set'lere bölünmesi.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 30)\n",
            "(455, 1)\n",
            "(114, 30)\n",
            "(114, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2AQEhfUbDxPt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8a2c38e9-09b6-4252-a0ac-f18b4b172db0"
      },
      "source": [
        "# train ve test set'lerdeki bağımlı değişkenin benzer şekilde dağılıp dağılmadığının kontrol edilmesi.\n",
        "print(y_train.mean())\n",
        "print(y_test.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target    0.626374\n",
            "dtype: float64\n",
            "target    0.631579\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6RSffdrDxP1"
      },
      "source": [
        "# Adaboost'ta derinliği olmayan ufak karar ağaçları kullanıyorduk. Maksimum kırılımı 2 olan karar ağacı oluşturalım.\n",
        "shallow_tree = DecisionTreeClassifier(max_depth=2, random_state = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQDfeBxtDxP5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18850fca-eb06-44d2-e82b-d7c62cbb00a1"
      },
      "source": [
        "# modeli öğrenelim.\n",
        "shallow_tree.fit(X_train, y_train)\n",
        "\n",
        "# test hatalarının ekrana bastırılması.\n",
        "y_pred = shallow_tree.predict(X_test)\n",
        "score = metrics.accuracy_score(y_test, y_pred)\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9385964912280702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL9deIZmDxP-"
      },
      "source": [
        "Şimdi de adaboost'ta 1'den 50'ye kadar 3'er 3'er artacak şekilde farklı sayılarda weak learner ile sınıflama yapalım."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6htZfNKDxP_"
      },
      "source": [
        "# olası ağaç sayılarını tutacak olan listenin oluşturulması.\n",
        "\n",
        "estimators = list(range(1, 50, 3))\n",
        "\n",
        "abc_scores = []\n",
        "for n_est in estimators:\n",
        "    ABC = AdaBoostClassifier(\n",
        "    base_estimator=shallow_tree, \n",
        "    n_estimators = n_est)\n",
        "    \n",
        "    ABC.fit(X_train, y_train)\n",
        "    y_pred = ABC.predict(X_test)\n",
        "    score = metrics.accuracy_score(y_test, y_pred)\n",
        "    abc_scores.append(score)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VyTbhOIDxQD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "1ac0f4ba-4395-4c13-a631-d7746154b6a0"
      },
      "source": [
        "abc_scores # Farklı adaboost modellerinin tutarlılık sonuçları."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9473684210526315,\n",
              " 0.9298245614035088,\n",
              " 0.9473684210526315,\n",
              " 0.9736842105263158,\n",
              " 0.9649122807017544,\n",
              " 0.956140350877193,\n",
              " 0.9649122807017544,\n",
              " 0.9649122807017544,\n",
              " 0.956140350877193,\n",
              " 0.956140350877193,\n",
              " 0.9649122807017544,\n",
              " 0.9824561403508771,\n",
              " 0.9649122807017544,\n",
              " 0.9736842105263158,\n",
              " 0.9649122807017544,\n",
              " 0.9824561403508771,\n",
              " 0.9824561403508771]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xHqNC41DxQI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "131d8b2b-a608-4ef7-da41-74fd2fb03768"
      },
      "source": [
        "# test accuracy'lerinin plot'una bakarsak weak learner sayısı arttıkça modelin test verisindeki başarısının arttığını söyleyebiliriz.\n",
        "\n",
        "plt.plot(estimators, abc_scores)\n",
        "plt.xlabel('n_estimators')\n",
        "plt.ylabel('accuracy')\n",
        "plt.ylim([0.85, 1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}